# GPUStack LLM UI Interface

A simple interface for interacting with GPUStack using local LLMs, supporting:
- File uploads (PDF, DOCX, TXT, etc.)
- Web search via Tavily
- Streamed chat responses

## Setup

1. Clone repo
2. Install dependencies:
   ```bash
   cd backend && pip install -r requirements.txt
   cd ../frontend && npm install

